{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS440/ECE448 Spring 2023\n",
    "# MP02: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is to download this file: <a href=\"mp02.zip\">mp02.zip</a>.    Content is similar to MP01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file (`mp02_notebook.ipynb`) will walk you through the whole MP, giving you instructions and debugging tips as you go.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">Reading the Data</a>\n",
    "1. <a href=\"#section2\">Learning a Naive Bayes Model: Maximum Likelihood</a>\n",
    "1. <a href=\"#section3\">Learning a Naive Bayes Model: Stop Words</a>\n",
    "1. <a href=\"#section4\">Learning a Naive Bayes Model: Laplace Smoothing</a>\n",
    "1. <a href=\"#section5\">Decisions Using a Naive Bayes Model</a>\n",
    "1. <a href=\"#section6\">Optimizing Hyperparameters</a>\n",
    "1. <a href=\"#grade\">Grade Your Homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset in your template package consists of 10000 positive and 3000 negative movie reviews. It is a subset of the <a href=\"https://ai.stanford.edu/~amaas/data/sentiment/\">Stanford Movie Review Dataset</a>, which was originally introduced by <a href=\"https://www.aclweb.org/anthology/P11-1015\">this paper</a>. We have split this data set for you into 5000 development examples and 8000 training examples. The autograder also has a hidden set of test examples, generally similar to the development dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data folder is structured like this:\n",
    "\n",
    "```\n",
    "  ├─ train\n",
    "  │   ├─ neg\n",
    "  │   │   └─ 2000 negative movie reviews (text)\n",
    "  │   └─ pos\n",
    "  │       └─ 6000 positive movie reviews (text)\n",
    "  └─ dev\n",
    "      ├─ neg\n",
    "      │   └─ 1000 negative movie reviews (text)\n",
    "      └─ pos\n",
    "  │       └─ 4000 positive movie reviews (text)\n",
    "```\n",
    "\n",
    "In order to help you load the data, we provide you with a utility function called `reader.py`.  This has two new functions that didn't exist in mp01:\n",
    "\n",
    "* loadTrain: load a training set\n",
    "* loadDev: load a dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function loadTrain in module reader:\n",
      "\n",
      "loadTrain(dirname, stemming, lower_case, use_tqdm=True)\n",
      "    Loads a training dataset.\n",
      "    \n",
      "    Parameters:\n",
      "    dirname (str): the directory containing the data\n",
      "        - dirname/y should contain training examples from class y\n",
      "    \n",
      "    stemming (bool): if True, use NLTK's stemmer to remove suffixes\n",
      "    lower_case (bool): if True, convert letters to lowercase\n",
      "    use_tqdm (bool, default:True): if True, use tqdm to show status bar\n",
      "    \n",
      "    Output:\n",
      "    train (dict of list of lists): \n",
      "        - train[y][i][k] = k'th token of i'th text of class y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import reader, importlib\n",
    "importlib.reload(reader)\n",
    "help(reader.loadTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the text files have not been lowercased for you in advance, so you probably want to lowercase them using the `lower_case` bool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2116.82it/s]\n",
      "100%|██████████| 6000/6000 [00:02<00:00, 2268.81it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(reader)\n",
    "\n",
    "train = reader.loadTrain('data/train', False, True, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2000 texts loaded for class neg\n",
      "There were 6000 texts loaded for class pos\n"
     ]
    }
   ],
   "source": [
    "for y in train.keys():\n",
    "    print(\"There were\",len(train[y]),\"texts loaded for class\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first positive review is: ['i', 'went', 'and', 'saw', 'this', 'movie', 'last', 'night', 'after', 'being', 'coaxed', 'to', 'by', 'a', 'few', 'friends', 'of', 'mine', 'i', 'll', 'admit', 'that', 'i', 'was', 'reluctant', 'to', 'see', 'it', 'because', 'from', 'what', 'i', 'knew', 'of', 'ashton', 'kutcher', 'he', 'was', 'only', 'able', 'to', 'do', 'comedy', 'i', 'was', 'wrong', 'kutcher', 'played', 'the', 'character', 'of', 'jake', 'fischer', 'very', 'well', 'and', 'kevin', 'costner', 'played', 'ben', 'randall', 'with', 'such', 'professionalism', 'the', 'sign', 'of', 'a', 'good', 'movie', 'is', 'that', 'it', 'can', 'toy', 'with', 'our', 'emotions', 'this', 'one', 'did', 'exactly', 'that', 'the', 'entire', 'theater', 'which', 'was', 'sold', 'out', 'was', 'overcome', 'by', 'laughter', 'during', 'the', 'first', 'half', 'of', 'the', 'movie', 'and', 'were', 'moved', 'to', 'tears', 'during', 'the', 'second', 'half', 'while', 'exiting', 'the', 'theater', 'i', 'not', 'only', 'saw', 'many', 'women', 'in', 'tears', 'but', 'many', 'full', 'grown', 'men', 'as', 'well', 'trying', 'desperately', 'not', 'to', 'let', 'anyone', 'see', 'them', 'crying', 'this', 'movie', 'was', 'great', 'and', 'i', 'suggest', 'that', 'you', 'go', 'see', 'it', 'before', 'you', 'judge']\n"
     ]
    }
   ],
   "source": [
    "print(\"The first positive review is:\",train['pos'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Naive Bayes Model: Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand Naive Bayes, it might be useful to know the difference between word types and word tokens.\n",
    "\n",
    "* **token:** The word tokens are the elements of the list.  The number of word tokens in the $n^{\\text{th}}$ positive text is `len(train['pos'][n])`.\n",
    "* **type:** The word types are the list of unique words that occurred in a review.  The number of word types in the $n^{\\text{th}}$ positive text is `len(set(train['pos'][n]))`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Naive Bayes model consists of two types of probability distributions:\n",
    "\n",
    "* The **prior** is the distribution over classes, $P(\\text{Class})$.\n",
    "* The **likelihood** is the probability of a word token given a particular class, $P(\\text{Token}|\\text{Class})$.\n",
    "\n",
    "The prior can be estimated from the training data.  In your training data, $P(\\text{Class}=\\text{pos})=0.75$.  \n",
    "\n",
    "Often, though, the testing data will have a different class distribution than the training data.  If you don't know the testing priors, then it's sometimes best to just assume a uniform distribution, i.e., $P(\\text{Class}=\\text{pos})=0.5$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood is the informative part of a Naive Bayes model: it tells you which words are used more often in negative versus positive movie reviews.\n",
    "\n",
    "There are many ways in which you can estimate the likelihood.  The following formula is called the **maximum likelihood** estimate, because it maximizes the likelihood of the words in your training dataset:\n",
    "\n",
    "$$P(\\text{Token}=x|\\text{Class}=y)=\\frac{\\text{# tokens of word}~x~\\text{in texts of class}~y}{\\text{# tokens of any word in texts of class}~y}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the MP, you will estimate what are called **frequency tables**.  The frequency of $x$ given $y$ is the number of times that word $x$ occurred in texts of class $y$.  The relevant method in `submitted.py` is the one called `create_frequency_table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_frequency_table in module submitted:\n",
      "\n",
      "create_frequency_table(train)\n",
      "    Parameters:\n",
      "    train (dict of list of lists) \n",
      "        - train[y][i][k] = k'th token of i'th text of class y\n",
      "    \n",
      "    Output:\n",
      "    frequency (dict of Counters) \n",
      "        - frequency[y][x] = number of tokens of word x in texts of class y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import submitted, importlib\n",
    "importlib.reload(submitted)\n",
    "help(submitted.create_frequency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `create_frequency_table` so that it does what its docstring says it should do.  \n",
    "\n",
    "**Hint:** your code will be shorter if you use the python data structure called a <a href=\"https://docs.python.org/3/library/collections.html#collections.Counter\">Counter</a>.\n",
    "\n",
    "When your code works, you should get the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency['pos']['excellent']= 810\n",
      "frequency['neg']['excellent']= 61\n",
      "\n",
      "\n",
      "Total # tokens in pos texts is 1427513\n",
      "Total # tokens in neg texts is 470194\n",
      "\n",
      "\n",
      "Total # types in pos texts is 40829\n",
      "Total # types in neg texts is 23901\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "frequency = submitted.create_frequency_table(train)\n",
    "\n",
    "print(\"frequency['pos']['excellent']=\",frequency['pos']['excellent'])\n",
    "print(\"frequency['neg']['excellent']=\",frequency['neg']['excellent'])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Total # tokens in pos texts is\",sum(frequency['pos'].values()))\n",
    "print(\"Total # tokens in neg texts is\",sum(frequency['neg'].values()))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Total # types in pos texts is\",len(frequency['pos'].keys()))\n",
    "print(\"Total # types in neg texts is\",len(frequency['neg'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Naive Bayes model: Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here are a lot of common words, like \"is, of, and\", that seem to be obviously unrelated to whether a movie review is positive or negative.  Because of the way the database was collected, though, it's possible that some of those words are much more frequent in one part of the training data than another.  That's bad, because it means that a test review might be classified as \"positive\" just because it contains many examples of an innocuous word like \"is\".\n",
    "\n",
    "A \"stopword list\" is a list of words that should not be considered when you classify a test text.  There are many candidate stopword lists available on the internet.  The stopword list that we've provided for you is based on this one: https://www.ranks.nl/stopwords\n",
    "\n",
    "Here is our stopword list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'t\", \"'ve\", 'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'cannot', 'could', 'couldn', 'did', 'didn', 'do', 'does', 'doesn', 'doing', 'don', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', 'has', 'hasn', 'have', 'haven', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', 'it', 'its', 'itself', 'let', 'll', 'me', 'more', 'most', 'mustn', 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', 'shan', 'she', 'should', 'shouldn', 'so', 'some', 'such', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', 'wasn', 'we', 'were', 'weren', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'with', 'won', 'would', 'wouldn', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "print(sorted(submitted.stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid counting stopwords, two steps are necessary:\n",
    "\n",
    "1. Pretend that their frequency in the training corpus is zero,\n",
    "1. Ignore them if they occur in testing data.\n",
    "\n",
    "In this part of the MP, you should set the frequencies of those stopwords to zero.  Use the `del` command (see <a href=\"https://docs.python.org/3/library/collections.html#collections.Counter\">Counters</a>), so that these words don't get counted among either the word types or the word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function remove_stopwords in module submitted:\n",
      "\n",
      "remove_stopwords(frequency)\n",
      "    Parameters:\n",
      "    frequency (dict of Counters) \n",
      "        - frequency[y][x] = number of tokens of word x in texts of class y\n",
      "    \n",
      "    Output:\n",
      "    nonstop (dict of Counters) \n",
      "        - nonstop[y][x] = frequency of word x in texts of class y,\n",
      "          but only if x is not a stopword.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequency['pos']['excellent']= 810\n",
      "nonstop['pos']['excellent']= 810\n",
      "\n",
      "\n",
      "frequency['pos']['you']= 7917\n",
      "nonstop['pos']['you']= 0\n",
      "\n",
      "\n",
      "Total pos frequency: 1427513\n",
      "Total pos non-stopwords 769662\n",
      "\n",
      "\n",
      "Total # types in pos texts is 40829\n",
      "Total # non-stopwords in pos is 40687\n",
      "Length of the stopwords set is: 150\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "nonstop = submitted.remove_stopwords(frequency)\n",
    "\n",
    "print(\"frequency['pos']['excellent']=\",frequency['pos']['excellent'])\n",
    "print(\"nonstop['pos']['excellent']=\",nonstop['pos']['excellent'])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"frequency['pos']['you']=\",frequency['pos']['you'])\n",
    "print(\"nonstop['pos']['you']=\",nonstop['pos']['you'])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Total pos frequency:\",sum(frequency['pos'].values()))\n",
    "print(\"Total pos non-stopwords\",sum(nonstop['pos'].values()))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Total # types in pos texts is\",len(frequency['pos'].keys()))\n",
    "print(\"Total # non-stopwords in pos is\",len(nonstop['pos'].keys()))\n",
    "\n",
    "print(\"Length of the stopwords set is:\",len(submitted.stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Naive Bayes model: Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood formula results in some words having zero probability, just because they were not contained in your training data.  A better formula is given by Laplace smoothing, according to which\n",
    "\n",
    "$$P(\\text{Token}=x|\\text{Class}=y)=\\frac{\\left(\\text{# tokens of word}~x~\\text{in texts of class}~y\\right)+k}{\\left(\\text{# tokens of any word in texts of class}~y\\right)+k\\times\\left(\\text{# of word types}+1\\right)}$$\n",
    "\n",
    "...where $k$ is a hyperparameter that is usually chosen by trying several different values, and choosing the value that gives you the best accuracy on your development dataset.  \n",
    "\n",
    "The `+1` in the denominator is used to account for words that were never seen in the training dataset for class $y$.  All such words are mapped to the type `OOV` (out of vocabulary), which has the likelihood\n",
    "\n",
    "$$P(\\text{Token}=\\text{OOV}|\\text{Class}=y)=\\frac{k}{\\left(\\text{# tokens of any word in texts of class}~y\\right)+k\\times\\left(\\text{# of word types}+1\\right)}$$\n",
    "\n",
    "In this part of the MP, the method you'll create in `submitted.py` is called `laplace_smoothing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function laplace_smoothing in module submitted:\n",
      "\n",
      "laplace_smoothing(nonstop, smoothness)\n",
      "    Parameters:\n",
      "    nonstop (dict of Counters) \n",
      "        - nonstop[y][x] = frequency of x in y, if x not a stopword\n",
      "    smoothness (float)\n",
      "        - smoothness = Laplace smoothing hyperparameter\n",
      "    \n",
      "    Output:\n",
      "    likelihood (dict of dicts) \n",
      "        - likelihood[y][x] = Laplace-smoothed likelihood of x given y\n",
      "        - likelihood[y]['OOV'] = likelihood of an out-of-vocabulary word given y\n",
      "    \n",
      "    Be careful that your vocabulary only counts words that occurred at least once\n",
      "    in the training data for class y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.laplace_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood['pos']['excellent']= 0.0005523232650681755\n",
      "likelihood['neg']['excellent']= 0.00012548168776917846\n",
      "\n",
      "\n",
      "likelihood['pos']['OOV']= 6.810397843010795e-07\n",
      "likelihood['neg']['OOV']= 2.023898189825459e-06\n",
      "\n",
      "\n",
      "likelihood['pos'] sums to 0.9999999999996005\n",
      "Likelihood['neg'] sums to 0.9999999999996396\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "likelihood = submitted.laplace_smoothing(frequency, 1)\n",
    "\n",
    "print(\"likelihood['pos']['excellent']=\",likelihood['pos']['excellent'])\n",
    "print(\"likelihood['neg']['excellent']=\",likelihood['neg']['excellent'])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"likelihood['pos']['OOV']=\",likelihood['pos']['OOV'])\n",
    "print(\"likelihood['neg']['OOV']=\",likelihood['neg']['OOV'])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"likelihood['pos'] sums to\",sum(likelihood['pos'].values()))\n",
    "print(\"Likelihood['neg'] sums to\",sum(likelihood['neg'].values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions using a Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are given a text, which is just a list of word tokens, $x=[x_1,\\ldots,x_n]$.  You want to decide whether this text is a positive movie review or a negative review.  According to decision theory, the probability of error is minimized by the following rule:\n",
    "\n",
    "$$\\text{Estimated Class}=\\left\\{\\begin{array}{ll}\n",
    "\\text{pos}~\\text{if}~P(\\text{Class}=\\text{pos}|\\text{Text}=x) > \n",
    "P(\\text{Class}=\\text{neg}|\\text{Text}=x)\\\\\n",
    "\\text{neg}~\\text{if}~P(\\text{Class}=\\text{pos}|\\text{Text}=x) < \n",
    "P(\\text{Class}=\\text{neg}|\\text{Text}=x)\\\\\n",
    "\\text{undecided}~\\text{if}~P(\\text{Class}=\\text{pos}|\\text{Text}=x) = \n",
    "P(\\text{Class}=\\text{neg}|\\text{Text}=x)\\end{array}\\right.$$\n",
    "\n",
    "The posterior probabilities $P(\\text{Class}|\\text{Text})$ can be estimated using the Naive Bayes model:\n",
    "\n",
    "$$P(\\text{Class}=y|\\text{Text}=x)=\\frac{P(\\text{Class}=y)}{P(\\text{Text}=x)}\\prod_{i\\not\\in\\text{stopwords},i=1}^nP(\\text{Token}=x_i|\\text{Class}=y)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation Details\n",
    "\n",
    "Notice some details:\n",
    "1. The term $P(\\text{Text}=x)$ doesn't depend on $y$.  If you're trying to figure out which is bigger, $P(\\text{pos}|x)$ or $P(\\text{neg}|x)$, then you don't need to calculate it.\n",
    "1. Multiplying together $n$ probabilities will result in a number that your computer might round down to 0.  In order to prevent that, take the logarithm of both sides of the equation above.\n",
    "1. If $x_i$ is a stopword, don't calculate its likelihood.  If it isn't a stopword, but it doesn't have an entry in `likelihood[y]`, then you should use `likelihood[y][\"OOV\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation\n",
    "\n",
    "For this part of the MP, finish the method called `submitted.naive_bayes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function naive_bayes in module submitted:\n",
      "\n",
      "naive_bayes(texts, likelihood, prior)\n",
      "    Parameters:\n",
      "    texts (list of lists) -\n",
      "        - texts[i][k] = k'th token of i'th text\n",
      "    likelihood (dict of dicts) \n",
      "        - likelihood[y][x] = Laplace-smoothed likelihood of x given y\n",
      "    prior (float)\n",
      "        - prior = the prior probability of the class called \"pos\"\n",
      "    \n",
      "    Output:\n",
      "    hypotheses (list)\n",
      "        - hypotheses[i] = class label for the i'th text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.naive_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `reader.loadDev` to load the dev set, then try classifying it with, say, a prior of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1997.67it/s]\n",
      "100%|██████████| 4000/4000 [00:01<00:00, 2247.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 examples of class neg\n",
      "There are 4000 examples of class pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(reader)\n",
    "texts, labels = reader.loadDev('data/dev', False, True, True)\n",
    "\n",
    "for y in ['neg','pos']:\n",
    "    print(\"There are\",labels.count(y),'examples of class',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2016 examples that were labeled with class neg\n",
      "There are 2984 examples that were labeled with class pos\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "hypotheses = submitted.naive_bayes(texts, likelihood, 0.5)\n",
    "\n",
    "for y in ['neg','pos']:\n",
    "    print(\"There are\",hypotheses.count(y),'examples that were labeled with class',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the dev set is:\n",
      "0.7744\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the classifier on the dev set is:\")\n",
    "\n",
    "count_correct = 0\n",
    "for (y,yhat) in zip(labels, hypotheses):\n",
    "    if y==yhat:\n",
    "        count_correct += 1\n",
    "        \n",
    "print(count_correct / len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the model is heavily influenced by two parameters that can't be measured from the training data:\n",
    "\n",
    "1. The prior, $P(\\text{Class}=\\text{pos})$.  The training and testing data might have different priors, so estimating this from the training data is suboptimal.\n",
    "1. The Laplace smoothing parameter, $k$.\n",
    "\n",
    "Since these two parameters can't be (correctly) estimated from the training data, they are called **hyperparameters**.  Hyperparameters are usually determined based on your knowledge about the problem, or by running a lot of experiments to see which values give the best result on the development test data.\n",
    "\n",
    "The function you'll write in this part of the MP is called `optimize_hyperparameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function optimize_hyperparameters in module submitted:\n",
      "\n",
      "optimize_hyperparameters(texts, labels, nonstop, priors, smoothnesses)\n",
      "    Parameters:\n",
      "    texts (list of lists) - dev set texts\n",
      "        - texts[i][k] = k'th token of i'th text\n",
      "    labels (list) - dev set labels\n",
      "        - labels[i] = class label of i'th text\n",
      "    nonstop (dict of Counters) \n",
      "        - nonstop[y][x] = frequency of word x in class y, x not stopword\n",
      "    priors (list)\n",
      "        - a list of different possible values of the prior\n",
      "    smoothnesses (list)\n",
      "        - a list of different possible values of the smoothness\n",
      "    \n",
      "    Output:\n",
      "    accuracies (numpy array, shape = len(priors) x len(smoothnesses))\n",
      "        - accuracies[m,n] = dev set accuracy achieved using the\n",
      "          m'th candidate prior and the n'th candidate smoothness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.optimize_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to test some different candidate values for the prior and the smoothness.  The values we test are a little arbitrary, but let's try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy achieved was 0.8732\n",
      "It was achieved for a prior of 0.85\n",
      "  and a smoothness of 0.01\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "import numpy as np\n",
    "\n",
    "priors = [0.65,0.75,0.85]\n",
    "smoothnesses = [0.001,0.01,0.1]\n",
    "accuracies = submitted.optimize_hyperparameters(texts,labels,nonstop,priors,smoothnesses)\n",
    "\n",
    "(m,n) = np.unravel_index(np.argmax(accuracies), accuracies.shape)\n",
    "print(\"The best accuracy achieved was\",accuracies[m,n])\n",
    "print(\"It was achieved for a prior of\",priors[m])\n",
    "print(\"  and a smoothness of\",smoothnesses[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "contours = ax.contour(smoothnesses, priors, accuracies)\n",
    "ax.clabel(contours, inline=True, fontsize=10)\n",
    "ax.set_title('Devset accuracy versus smoothness and prior')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade your homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've reached this point, and all of the above sections work, then you're ready to try grading your homework!  Before you submit it to Gradescope, try grading it on your own machine.  This will run some visible test cases (which you can read in `tests/test_visible.py`), and compare the results to the solutions (which you can read in `solution.json`).\n",
    "\n",
    "The exclamation point (!) tells python to run the following as a shell command.  Obviously you don't need to run the code this way -- this usage is here just to remind you that you can also, if you wish, run this command in a terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 51.523s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got any 'E' marks, it means that your code generated some runtime errors, and you need to debug those.\n",
    "\n",
    "If you got any 'F' marks, it means that your code ran without errors, but that it generated results that are different from the solutions in `solutions.json`.  Try debugging those differences.\n",
    "\n",
    "If neither of those things happened, and your result was a series of dots, then your code works perfectly.  \n",
    "\n",
    "If you're not sure, you can try running grade.py with the -j option.  This will produce a JSON results file, in which the best score you can get is 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should try uploading `submitted.py` to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.  \n",
    "\n",
    "Gradescope will run the same visible tests that you just ran on your own machine, plus some additional hidden tests.  It's possible that your code passes all the visible tests, but fails the hidden tests.  If that happens, then it probably means that you hard-coded a number into your function definition, instead of using the input parameter that you were supposed to use.  Debug by running your function with a variety of different input parameters, and see if you can get it to respond correctly in all cases.\n",
    "\n",
    "Once your code works perfectly on Gradescope, with no errors, then you are done with the MP.  Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
